{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **What is Subclassing in Tensorflow?**"
      ],
      "metadata": {
        "id": "_sXgqIql9tXW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRNsXgv49F9Y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.dense1 = layers.Dense(128, activation= 'relu')\n",
        "    self.dense2 = layers.Dense(64, activation = 'relu')\n",
        "    self.output_layer = layers.Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.dense1(inputs)\n",
        "    x = self.dense2(x)\n",
        "    return self.output_layer(x)"
      ],
      "metadata": {
        "id": "8iuj2UK3-IEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating using the model\n",
        "model = MyModel()\n",
        "\n",
        "# Example Input\n",
        "input_data = tf.random.normal([32,784]) # Batch of 32 samples, each of 784 features\n",
        "\n",
        "# forward pass\n",
        "output = model(input_data)\n",
        "\n",
        "# Check output shape\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHUCVsca-umC",
        "outputId": "9639dd08-1bab-4105-a670-7d09d6b267ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the custom training loop.\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# Custom training step\n",
        "\n",
        "@tf.function\n",
        "def train_step(model,images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training = True)\n",
        "    loss = loss_fn(labels, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "j8Q1gBSi_M-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "\n",
        "# load MNIST dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "# x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "# create Tensorflow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
        "test_dataset = train_dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "  for images, labels in train_dataset:\n",
        "    images = tf.reshape(images, [-1, 784]) # Flatten the images\n",
        "    loss = train_step(model, images, labels)\n",
        "  print(f\"Loss: {loss.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_Ilm-TF_xat",
        "outputId": "1091ad0f-18a5-4435-a183-a0893a17de31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py:635: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.02893536537885666\n",
            "Epoch 2/10\n",
            "Loss: 0.06303180754184723\n",
            "Epoch 3/10\n",
            "Loss: 0.03357594460248947\n",
            "Epoch 4/10\n",
            "Loss: 0.006820914335548878\n",
            "Epoch 5/10\n",
            "Loss: 0.007841427810490131\n",
            "Epoch 6/10\n",
            "Loss: 0.021507922559976578\n",
            "Epoch 7/10\n",
            "Loss: 0.0003730443713720888\n",
            "Epoch 8/10\n",
            "Loss: 0.00013930546992924064\n",
            "Epoch 9/10\n",
            "Loss: 0.0009413263760507107\n",
            "Epoch 10/10\n",
            "Loss: 0.0001044063683366403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "43E3WyjwAaHA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}